SEED: 10                      # random seed
GPU: [0]                      # list of gpu ids
DEBUG: 0                      # turn on debugging mode or not (0: off, 1: on)

DATA: CIFAR10                 # alias of dataset
ROOT_DIR: '/home/peiyu/workspace/UNetDiff/workspace/data/CIFAR10'
TRAIN_SPLIT: 0                # which data-split to use (-1: all, 0: training, 2: testing)
VAL_SPLIT: 1 
TEST_SPLIT: 1

LR: 0.0001                    # learning rate    
BETA1': 0.5                   # adam optimizer beta1
BETA2': 0.999                 # adam optimizer beta2
BATCH_SIZE: 64                # input batch size for training
INPUT_SIZE: 32                # input image size for training
INPUT_DIM: 3                  # input image dim for training
MAX_ITERS: 2e6                # maximum number of iterations to train the model

BETA_ST: 0.0002               # hyper-parameter for noise decay schedule
BETA_ED: 0.01                 # hyper-parameter for noise decay schedule
MAX_T: 6                      # number of noise levels (0: plain U-Net VAE)
UPDATE_FREQ: 10               # how many iterations to wait before reducing noise level
LAT_DIM: 64                   # dimension of latent vector
USE_SPC_NORM: 0               # use spectral normalization or not (0: off, 1: on)
INIT_WEIGHTS: 0               # use specified weight initialization or not (0: off, 1: on)

SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)
SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)
SAMPLE_SIZE: 12               # number of images to sample
EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)
LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)
